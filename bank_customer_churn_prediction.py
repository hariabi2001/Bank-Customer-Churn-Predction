# -*- coding: utf-8 -*-
"""Bank Customer Churn Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gU5BdvSB_BUs7Qm4tiGDeFqkB3kqf7yH
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
# %matplotlib inline

df = pd.read_csv("Churn_Modelling.csv")
df.sample(5)

"""# Data Cleaning

# Data Exploration
"""

# RowNumber, CustomerId and Surname is useless [when building ML model]
df.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)

df.dtypes # All columns along with their types

df.shape

df.describe()

"""# Visualization"""

# Tenure => How loyal your customer is, How many of loyal customers leaving
tenure_churn_no = df[df.Exited==0].Tenure
tenure_churn_yes = df[df.Exited==1].Tenure

# Plotting the histogram with persons leaving and staying in the service
plt.xlabel('Tenure')
plt.ylabel('Number of Customers')
plt.title("Customer Churn Prediction Visualization")

plt.hist([tenure_churn_yes, tenure_churn_no], color = ['green','red'], label = ['Exited = 1','Exited = 0'])
plt.legend()

# Estimated Salary is high customers may leave
es_churn_no = df[df.Exited==0].EstimatedSalary
es_churn_yes = df[df.Exited==1].EstimatedSalary

# Plotting the histogram with persons leaving and staying in the service
plt.xlabel('Estimated Salary')
plt.ylabel('Number of Customers')
plt.title("Customer Churn Prediction Visualization")

plt.hist([es_churn_yes, es_churn_no], color = ['green','red'])
plt.legend()

# Exited = 1 [Leaving] (Green in graph)
# Exited = 0 [Not Leaving] (Red in graph)

"""# Label Encoding"""

# Unique values in each of the column
def print_unique_col_values(df):
    for column in df:
        if df[column].dtypes=='object': # Checking the column is categorical
            print(f'{column} : {df[column].unique()}')

print_unique_col_values(df)

df['Gender'].replace({'Female':1, 'Male':0}, inplace = True)

df['Gender'].unique()

# One Hot Encoding
# Create dummy variables and create columns
df1 = pd.get_dummies(data = df, columns = ['Geography'])
df1.columns

df1.sample(4)

df1.dtypes

"""# Feature Scaling"""

# CreditScore, Balance, Tenure and EstimatedSalary are in different ranges
# Scale the values so that it comes to 0 to 1

cols_to_scale = ['CreditScore', 'Balance', 'Tenure', 'EstimatedSalary']

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])

df1.sample(3)

for col in df1:
  print(f'{col} : {df1[col].unique()}')

"""# Train Test Split"""

X = df1.drop('Exited', axis = 'columns')
y = df1['Exited']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

X_train.shape

X_test.shape

X_train[:10]

len(X_train.columns)

import tensorflow as tf
from tensorflow import keras

model = keras.Sequential([
    # Input layer, No of neurons => No of columns (12)
    # Each neuron in the input layer is accepting one feature
    # First layer (Hidden layer)
    keras.layers.Dense(7, input_shape = (12,), activation = 'relu'),
    # Output layer
    keras.layers.Dense(1, activation = 'sigmoid')
])

# Compilation of model
# Loss => Binarycrossentropy because our output is binary (0/1)
model.compile(optimizer = 'adam',
              loss = 'binary_crossentropy',
              metrics = ['accuracy'])

model.fit(X_train, y_train, epochs = 100)

# Evaluate the model
model.evaluate(X_test, y_test)

# Predict the model [Testing]
yp = model.predict(X_test)
# As it is sigmoid function the values are between 0 and 1
yp[:5]

y_test[:10]

# Converting values of yp to 0 or 1
y_pred = []
for element in yp:
  if element > 0.5:
    y_pred.append(1)
  else:
    y_pred.append(0)

y_pred[:10]

# Statistics on precision and recall
# Plotting performance of overall model
from sklearn.metrics import confusion_matrix, classification_report

print(classification_report(y_test, y_pred))

import seaborn as sns
# Diagonal => Correct prediction, Not in Diagonal => Error
cm = tf.math.confusion_matrix(labels = y_test, predictions = y_pred)

plt.figure(figsize = (10,7))
sns.heatmap(cm, annot = True, fmt = 'd')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""# Accuracy"""

round((1561+67)/(1561+67+338+34),2)

"""# Precision for 0 class. i.e. Precision for customers who did not churn"""

# No of correct predictions you made for 0
# (Correctly predicted 0) / (Total predicted 0)
round(1561/(1561+338),2)

"""# Precision for 1 class. i.e. Precision for customers who actually churned"""

# No of correct predictions you made for 1
# (Correctly predicted 1) / (Total predicted 1)
round(67/(67+34),2)

"""# Recall for 0 class"""

# Total correct prediction for 0 / Total actual 0 samples
round(1561/(1561+34))

"""# Recall for 1 class"""

# Total correct prediction for 1 / Total actual 1 samples
round(67/(338+67),2)